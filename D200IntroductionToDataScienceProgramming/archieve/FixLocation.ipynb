{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#!pip install -r requirements.txt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import us\n",
    "import re\n",
    "import geocoder\n",
    "import regex\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_state_names = [\n",
    "    \"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"California\", \"Colorado\",\n",
    "    \"Connecticut\", \"Delaware\", \"Florida\", \"Georgia\", \"Hawaii\", \"Idaho\",\n",
    "    \"Illinois\", \"Indiana\", \"Iowa\", \"Kansas\", \"Kentucky\", \"Louisiana\",\n",
    "    \"Maine\", \"Maryland\", \"Massachusetts\", \"Michigan\", \"Minnesota\",\n",
    "    \"Mississippi\", \"Missouri\", \"Montana\", \"Nebraska\", \"Nevada\",\n",
    "    \"New Hampshire\", \"New Jersey\", \"New Mexico\", \"New York\", \"North Carolina\",\n",
    "    \"North Dakota\", \"Ohio\", \"Oklahoma\", \"Oregon\", \"Pennsylvania\",\n",
    "    \"South Carolina\", \"South Dakota\", \"Tennessee\", \"Texas\", \"Utah\",\n",
    "    \"Vermont\", \"Virginia\", \"Washington\", \"West Virginia\", \"Wisconsin\", \"Wyoming\"\n",
    "]\n",
    "us_states_abbr = {\n",
    "    \"Alabama\": \"AL\", \"Alaska\": \"AK\", \"Arizona\": \"AZ\", \"Arkansas\": \"AR\", \n",
    "    \"California\": \"CA\", \"Colorado\": \"CO\", \"Connecticut\": \"CT\", \n",
    "    \"Delaware\": \"DE\", \"Florida\": \"FL\", \"Georgia\": \"GA\", \"Hawaii\": \"HI\", \n",
    "    \"Idaho\": \"ID\", \"Illinois\": \"IL\", \"Indiana\": \"IN\", \"Iowa\": \"IA\", \n",
    "    \"Kansas\": \"KS\", \"Kentucky\": \"KY\", \"Louisiana\": \"LA\", \"Maine\": \"ME\", \n",
    "    \"Maryland\": \"MD\", \"Massachusetts\": \"MA\", \"Michigan\": \"MI\", \n",
    "    \"Minnesota\": \"MN\", \"Mississippi\": \"MS\", \"Missouri\": \"MO\", \n",
    "    \"Montana\": \"MT\", \"Nebraska\": \"NE\", \"Nevada\": \"NV\", \n",
    "    \"New Hampshire\": \"NH\", \"New Jersey\": \"NJ\", \"New Mexico\": \"NM\", \n",
    "    \"New York\": \"NY\", \"North Carolina\": \"NC\", \"North Dakota\": \"ND\", \n",
    "    \"Ohio\": \"OH\", \"Oklahoma\": \"OK\", \"Oregon\": \"OR\", \"Pennsylvania\": \"PA\", \n",
    "    \"Rhode Island\": \"RI\", \"South Carolina\": \"SC\", \"South Dakota\": \"SD\", \n",
    "    \"Tennessee\": \"TN\", \"Texas\": \"TX\", \"Utah\": \"UT\", \"Vermont\": \"VT\", \n",
    "    \"Virginia\": \"VA\", \"Washington\": \"WA\", \"West Virginia\": \"WV\", \n",
    "    \"Wisconsin\": \"WI\", \"Wyoming\": \"WY\"\n",
    "}\n",
    "us_state_correction = {\n",
    "        \"au large de la californie\": \"California\",\n",
    "        \"Pacifique\":\"California\",\n",
    "        \"au large de la Californie\":\"California\",\n",
    "        \"nouveau mexique\": \"New Mexico\",\n",
    "        \"chicago\": \"Illinois\",\n",
    "        \"los angeles\": \"California\",\n",
    "        \"swisher districts\": \"Texas\",\n",
    "        \"rhode isl. \": \"Rhode Island\",\n",
    "        \"near los angeles\": \"California\",\n",
    "        \"atlantic terminal station\": \"New York\",\n",
    "        \"north california\": \"None\",\n",
    "        \"los angeles\": \"California\",\n",
    "        \"jerauld\": \"South Dakota\",\n",
    "        \"jefferson davis\": \"Mississippi\",\n",
    "        \"nassau-florida\": \"Florida\",\n",
    "        \"wilkes\": \"North Carolina\",\n",
    "        \"noble in richland\": \"Illinois\",\n",
    "        \"marion-in\": \"Indiana\",\n",
    "        \"central michigan \": \"Michigan\",\n",
    "        \"south california\": \"California\",\n",
    "        \"south-western louisiana\": \"Louisiana\",\n",
    "        \"north california \": \"California\",\n",
    "        \"northern washington \": \"Washington\",\n",
    "        \"central-northern usa\": \"None\",\n",
    "        \"montana and idaho s\": \"None\",\n",
    "        \"hollywood\": \"California\",\n",
    "        \"eastern washington \": \"Washington\",\n",
    "        \"eastern new mexico\": \"New Mexico\",\n",
    "        \"district of columbia\":\"Washington, D.C.\",\n",
    "        \"Nouveau Mexique\" :\"New Mexico\",\n",
    "        \"Floride\" : \"Florida\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('location.csv',names=[\"Location\"])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_boundary(x):\n",
    "    if re.match(\".*south|north|east|west.*\", x.lower()):\n",
    "        print(\"..\",x)\n",
    "    if re.match(\"(.*);(.*)\", x.lower()): \n",
    "        multistate = x.split(\";\")\n",
    "        multistate_str = \"\"\n",
    "        for ms in multistate:\n",
    "            print(\"..\",ms,us.states.lookup(ms.strip()))\n",
    "            if us.states.lookup(ms.strip()):\n",
    "                state = us.states.lookup(ms).__str__()\n",
    "            else:\n",
    "                state =\"\"\n",
    "            multistate_str.join(state)\n",
    "            print(\"multistate\",multistate_str)\n",
    "        x=multistate_str\n",
    "    return x\n",
    "\n",
    "data['Location'].map(lambda x : state_boundary(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"Florida; Georgia; North Carolina; South Carol\"\n",
    "re.match(\".*south|north|east|west.*\", txt.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segregate_state(loc,df):\n",
    "    indx = data[data['Location'] == loc].index # Lets collect the index of this row to use it later in this section\n",
    "    \n",
    "    if not loc is np.nan:\n",
    "        loc_list = loc.split(';') # split all the location which contains ',' to segregate state(s)\n",
    "        if len(loc_list) == 0:\n",
    "            # This line is if the location contains valid state. no need to continue further.\n",
    "            if not us.states.lookup(loc.strip()):\n",
    "                state = us.states.lookup(loc).__str__()\n",
    "                df.loc[indx,\"Location\"] = state\n",
    "                print(\"Correct State single\",state)\n",
    "            return df\n",
    "\n",
    "        # Check if the row needs to be duplicated with more than one province\n",
    "        provinces = 0\n",
    "        state = \"\"\n",
    "        for ll in loc_list:\n",
    "            # call func\n",
    "            #segregate_state(indx,ll,data)\n",
    "   \n",
    "            matched = re.match('.*\\((.*)\\)',ll) # Match the brackets with regular expression\n",
    "            if 'province' in ll.lower() or ll.capitalize().strip() in us_state_names or ll.strip().lower() in us_state_correction.keys() or matched:\n",
    "                provinces+=1\n",
    "\n",
    "                if matched:\n",
    "                    state =matched[1]\n",
    "                else:\n",
    "                    print(\"stores as ,\",ll)\n",
    "                    state = ll\n",
    "                    state = re.sub(r\"state|provinces|province\", \"\", state).lower()\n",
    "                    state = re.sub(r\"\\)|\\(\", \"\", state).lower()\n",
    "                    print(\"Prov\",state)\n",
    "                if state in us_state_correction:\n",
    "                    print(\"incorrect\",state)\n",
    "                    state = us_state_correction[state] # Get the correct state name from the dictionary\n",
    "                    print(\"correct\",state)\n",
    "                if us.states.lookup(state.strip()):\n",
    "                    state = us.states.lookup(state).__str__()\n",
    "                if provinces >1:\n",
    "                    # We will duplicate the row with new state name\n",
    "                    new_df=df.iloc[indx].copy()\n",
    "                    new_df['Location_new'] = state.capitalize().strip()\n",
    "                    df=df._append([new_df],ignore_index=True)\n",
    "                else:                    \n",
    "                    state =state.capitalize().strip()\n",
    "                    df.loc[indx,\"Location_new\"] = state\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new\n",
    "#.explode('Location_new').reset_index(drop=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('location.csv',names=[\"Location\"])\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = '|'.join(['provinces', 'province'])\n",
    "\n",
    "data['Location'] = data['Location'].str.replace(pattern, '', regex=True)\n",
    "data['Location_new'] = data['Location'].apply(lambda x: \",\".join(re.findall(r'\\((.*?)\\)', x)))\n",
    "\n",
    "#data_new = data.explode('Location_new').reset_index(drop=True)\n",
    "#data['Location_new'] = data['Location'].apply(lambda x: \"; \".join(re.findall(r'\\((.*?)\\)', x)))\n",
    "# Explode the extracted list into multiple rows\n",
    "data.explode('Location_new').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_state(x):\n",
    "    if \"(\" in x:\n",
    "        #x = x.replace(\";\",\",\")\n",
    "        return re.findall(r'\\((.*?)\\)', x)\n",
    "    if \",\" in x:\n",
    "        return x.split(\",\")\n",
    "    return [x]\n",
    "\n",
    "# This line is if the location contains valid state. no need to continue further.\n",
    "def segregate_state(x):\n",
    "    x = re.sub(r'\\s+s$', '', x)\n",
    "    x = x.strip()\n",
    "    x = re.sub(r'and |near', '', x) \n",
    "    x = re.sub(r'^.*?,\\s*', '', x)\n",
    "    if x in us_state_correction.keys():\n",
    "        x = us_state_correction[x]\n",
    "    x_state = us.states.lookup(x).__str__()\n",
    "    if not x_state == 'None':\n",
    "        return x_state.capitalize().strip()\n",
    "    else:\n",
    "        # Find words that contain the substring\n",
    "        x_state = [st for st in us_states_abbr.keys() if  st.lower() in x]\n",
    "        if len(x_state) > 0:\n",
    "            return x_state\n",
    "        else:\n",
    "            return x\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segregate_state(x):\n",
    "    x = re.sub(r'\\s+s$', '', x)\n",
    "    x = x.strip()\n",
    "    x = re.sub(r'and |near', '', x) \n",
    "    x = re.sub(r'^.*?,\\s*', '', x)\n",
    "    if x in us_state_correction.keys():\n",
    "        x = us_state_correction[x]\n",
    "    x_state = us.states.lookup(x).__str__()\n",
    "    if not x_state == 'None':\n",
    "        return x_state.capitalize().strip()\n",
    "    else:\n",
    "        # Find words that contain the substring\n",
    "        x_state = [st for st in us_states_abbr.keys() if  st.lower() in x]\n",
    "        if len(x_state) > 0:\n",
    "            return x_state\n",
    "        else:\n",
    "            return x\n",
    "segregate_state(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words containing the substring: []\n"
     ]
    }
   ],
   "source": [
    "# List of words\n",
    "word_list = [\"apple\", \"banana\", \"cherry\", \"grape\", \"pineapple\"]\n",
    "# Part of word to check\n",
    "substring = \" bell s\"\n",
    "\n",
    "# Find words that contain the substring\n",
    "matching_words = [word for word in word_list if  word.lower() in substring]\n",
    "print(\"Words containing the substring:\", matching_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>Extracted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Crittenden, Daviess, Webster districts (Kentuc...</td>\n",
       "      <td>Kentucky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pacifique (au large de la Californie)</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bullock, Montgomery districts (Alabama ), Col...</td>\n",
       "      <td>Alabama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bullock, Montgomery districts (Alabama ), Col...</td>\n",
       "      <td>Georgia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bullock, Montgomery districts (Alabama ), Col...</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3239</th>\n",
       "      <td>Florida, Georgia, North Carolina, South Carol...</td>\n",
       "      <td>South carolina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3240</th>\n",
       "      <td>Florida, Georgia, North Carolina, South Carol...</td>\n",
       "      <td>Tennessee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3241</th>\n",
       "      <td>Florida, Georgia, North Carolina, South Carol...</td>\n",
       "      <td>Kentucly Virginia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3242</th>\n",
       "      <td>Hillsborough, Pinellas, Sarasota Volusia, Sai...</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3243</th>\n",
       "      <td>Roswell (Chaves county, Eastern New Mexico)</td>\n",
       "      <td>Eastern New Mexico</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3244 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Location           Extracted\n",
       "0     Crittenden, Daviess, Webster districts (Kentuc...            Kentucky\n",
       "1                 Pacifique (au large de la Californie)          California\n",
       "2      Bullock, Montgomery districts (Alabama ), Col...             Alabama\n",
       "3      Bullock, Montgomery districts (Alabama ), Col...             Georgia\n",
       "4      Bullock, Montgomery districts (Alabama ), Col...             Florida\n",
       "...                                                 ...                 ...\n",
       "3239   Florida, Georgia, North Carolina, South Carol...      South carolina\n",
       "3240   Florida, Georgia, North Carolina, South Carol...           Tennessee\n",
       "3241   Florida, Georgia, North Carolina, South Carol...   Kentucly Virginia\n",
       "3242   Hillsborough, Pinellas, Sarasota Volusia, Sai...             Florida\n",
       "3243        Roswell (Chaves county, Eastern New Mexico)  Eastern New Mexico\n",
       "\n",
       "[3244 rows x 2 columns]"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "data = pd.read_csv('location.csv',names=[\"Location\"])\n",
    "# Create the DataFrame\n",
    "#data = pd.DataFrame({'Location': [\"bullock; montgomery districts (alabama province); colquitt; grady; mitchell; thomas; tift districts (georgia province); washington district (floride province); lonoke; prairie; saline districts (arkansas province)\"]})\n",
    "pattern = '|'.join(['province', 'provinces','state','State','nan'])\n",
    "# Extract text inside parent heses and split by ';'\n",
    "data['Location'] = data['Location'].str.replace(pattern, '', regex=True)\n",
    "data['Location'] =data['Location'].replace(\";\",\",\",regex=True)\n",
    "#data['Extracted'] = data['Location'].apply(lambda x: re.findall(r'\\((.*?)\\)', x))\n",
    "data['Extracted'] = data['Location'].apply(extract_state)\n",
    "\n",
    "# Create a new DataFrame by stacking the split elements into new rows\n",
    "#exploded_df = pd.concat([pd.DataFrame({'Location': data.loc[idx, 'Location'], 'Extracted': item}, index=[idx]) \n",
    "#                         for idx, items in data['Extracted'].items() \n",
    "#                         for item in items]).reset_index(drop=True)\n",
    "# Explode the extracted list into multiple rows\n",
    "df_exploded = data.explode('Extracted').reset_index(drop=True)\n",
    "df_exploded['Extracted'] = df_exploded['Extracted'].apply(segregate_state)\n",
    "\n",
    "df_exploded.dropna(axis=0,inplace=True)\n",
    "df_exploded.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York\n",
      "North Dakota\n",
      "New Jersey\n",
      "New Hampshire\n",
      "South Carolina\n",
      "New Mexico\n",
      "North Carolina\n",
      "West Virginia\n",
      "South Dakota\n",
      "Rhode Island\n"
     ]
    }
   ],
   "source": [
    "uniq = df_exploded[df_exploded['Extracted'].isin(us_state_names)]['Extracted'].unique()\n",
    "difference2 = list(set(us_states_abbr.keys())-set(uniq))\n",
    "for diff in difference2:\n",
    "    print(f\"{diff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct \n"
     ]
    }
   ],
   "source": [
    "if \"Tennessee\" in df_exploded['Extracted'].to_list():\n",
    "    print(\"correct \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[380], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m difference2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(df_exploded[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExtracted\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_list()) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(us_states_abbr\u001b[38;5;241m.\u001b[39mkeys()))\n\u001b[1;32m      4\u001b[0m us_states \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAlabama\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAlaska\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArizona\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArkansas\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalifornia\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColorado\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnecticut\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDelaware\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFlorida\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGeorgia\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHawaii\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIdaho\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUtah\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVermont\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVirginia\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWashington\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWest Virginia\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWisconsin\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWyoming\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m ]\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m diff \u001b[38;5;129;01min\u001b[39;00m difference2:\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "\n",
    "difference2 = list(set(df_exploded['Extracted'].to_list()) - set(us_states_abbr.keys()))\n",
    "\n",
    "\n",
    "us_states = [\n",
    "    \"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"California\", \"Colorado\",\n",
    "    \"Connecticut\", \"Delaware\", \"Florida\", \"Georgia\", \"Hawaii\", \"Idaho\",\n",
    "    \"Illinois\", \"Indiana\", \"Iowa\", \"Kansas\", \"Kentucky\", \"Louisiana\",\n",
    "    \"Maine\", \"Maryland\", \"Massachusetts\", \"Michigan\", \"Minnesota\", \"Mississippi\",\n",
    "    \"Missouri\", \"Montana\", \"Nebraska\", \"Nevada\", \"New Hampshire\", \"New Jersey\",\n",
    "    \"New Mexico\", \"New York\", \"North Carolina\", \"North Dakota\", \"Ohio\", \"Oklahoma\",\n",
    "    \"Oregon\", \"Pennsylvania\", \"South Carolina\", \"South Dakota\", \"Tennessee\", \"Texas\",\n",
    "    \"Utah\", \"Vermont\", \"Virginia\", \"Washington\", \"West Virginia\", \"Wisconsin\", \"Wyoming\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for diff in difference2:\n",
    "    print(f\"original {diff}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "None\n",
      "as is  Rhode Isl.\n"
     ]
    }
   ],
   "source": [
    "x = \"Rhode Isl.\"\n",
    "print(type(x))\n",
    "x_state = us.states.lookup(x).__str__()\n",
    "#.capitalize().strip()\n",
    "print(x_state)\n",
    "if not x_state == 'None':\n",
    "    print(x_state)\n",
    "else:\n",
    "    print(\"as is \",x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best match for 'northern Texas': Texas with score 90\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_exploded['Extracted']=\n",
    "\n",
    "#df_exploded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('location.csv',names=[\"Location\"])\n",
    "# Function to extract the text inside parentheses\n",
    "def extract_state(location):\n",
    "    return re.findall(r'\\((.*?)\\)', location)  # Ensures the output is always a list\n",
    "\n",
    "# Apply cleaning and extraction\n",
    "pattern = '|'.join(['province', 'provinces', 'state'])\n",
    "data['Location'] = data['Location'].str.replace(pattern, '', regex=True)\n",
    "data['Extracted'] = data['Location'].apply(extract_state)\n",
    "\n",
    "# Explode the extracted list into multiple rows\n",
    "df_exploded = data.explode('Extracted').reset_index(drop=True)\n",
    "\n",
    "df_exploded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the following :\n",
    "# We have some states in brackets '()'\n",
    "# the state name is attached with text 'province' \n",
    "# The state name is attached with text 'state'\n",
    "# Some location column has more than one state combined in one row. We will duplicate those rows and add rows for each state in seperate rows\n",
    "# We will also fix letter cases.The capitalize() method returns a string where the first character is upper case, and the rest is lower case.\n",
    "\n",
    "#data_usa = data[data.Country == 'United States of America'].reset_index()\n",
    "locations=list(data['Location'])\n",
    "\n",
    "cnt = 0\n",
    "for loc in locations:\n",
    "    print(\"loc is \",loc)\n",
    "    # call func\n",
    "    data = segregate_state(loc,data)\n",
    "    cnt+=1\n",
    "    if cnt == 3:\n",
    "        \n",
    "        break\n",
    "\n",
    "data[\"Location\"] = data[\"Location\"].str.capitalize()   \n",
    "         \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#df = pd.DataFrame({'A': ['LOCAL FOREIGN', 'TEST FOREIGN', 'ANOTHER HELLO', 'NOTHING']})\n",
    " \n",
    "df = pd.DataFrame({'A': [\"bullock; montgomery districts (alabama province); colquitt; grady; mitchell; thomas; tift districts (georgia province); washington district (floride province); lonoke; prairie; saline districts (arkansas province)\"]})\n",
    "pattern = '|'.join(['LOCAL', 'FOREIGN', 'HELLO'])\n",
    "#print(df)\n",
    "df['A'] = df['A'].str.replace(pattern, 'CORP', regex=True)\n",
    "pattern = '|'.join(['province', 'provinces', '(',')'])\n",
    "df['A'] = df['A'].str.replace(pattern, '', regex=True)\n",
    "# Regex to extract only the words inside parentheses\n",
    "txt = \"bullock; montgomery districts (alabama province); colquitt; grady; mitchell; thomas; tift districts (georgia province); washington district (floride province); lonoke; prairie; saline districts (arkansas province)\"\n",
    "result = re.findall(r'\\((.*?)\\)', txt)\n",
    "\n",
    "# Join results into a single string if desired\n",
    "output = \"; \".join(result)\n",
    "#.replace(pattern,'',regex=True)\n",
    "df['A'].values\n",
    "output\n",
    "df['Extracted'] = df['A'].apply(lambda x: \"; \".join(re.findall(r'\\((.*?)\\)', x)))\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
